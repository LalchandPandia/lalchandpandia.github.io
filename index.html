<!DOCTYPE html>
<html lang="en">
<head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <!-- 83% allows portrait orientation to get the two-column format on an iPad (83% < 768/920) -->
    <meta name="viewport" content="width=device-width,initial-scale=0.83">
    <link rel="stylesheet" type="text/css" href="css/style.css">
    <title>Lalchand Pandia's Homepage</title>
</head>

<body>
	<div class="container">
        <div class="left-portion">
        	<div class="pic">
                <img class="image" src =" docs/myimage.jpg" />
            </div>
                <div class="contact">
                    <a href = mailto:lcpandia@uchicago.edu>Email</a><br>
            		<!--<a href = mailto:lcpandia@gmail.com>Email</a><br>-->
            		<a href ="docs/Lalchand_Pandia_CV.pdf">[CV]</a>
                </div>
            
        </div>
        <div class="bio" style='text-align:justify'>
         		<p>
                I am a 3rd year PhD student in computer science at the University of Chicago. I am fortunate to be advised by <a href="https://aetting.github.io/">Dr. Allyson Ettinger</a>
                 </p> 
                 <p> I also work closely with <a href="https://kanishka.website/"> Dr. Kanishka Misra.</a></p>
                <p>My research focus is on data-efficiency for learning i.e. selecting the best small subsets of data for training which not only maintains accuracy but also covers data diversity. I also work on how new concepts are encoded in LLM during their training.</p>
                <p>
                    Prior to joining UChicago, I was a software engineer in the industry, focusing on Distributed File Systems.
                </p>
            	 <p>I did my Masters in Computer Science  from <a href="http://www.cse.iitk.ac.in/">IIT, Kanpur</a>. 
                </p>
                <h2>Publications</h2>
                <ul>
                    <li>Sorting through the noise: Testing robustness of information processing in pre-trained language models</li>
                    <a href ="https://arxiv.org/abs/2109.12393">[pdf]</a> Accepted at EMNLP 2021
                    <li>Pragmatic competence of pre-trained language models through the lens of discourse connectives</li><a href="https://arxiv.org/abs/2109.12951">[pdf]</a> Accepted at CoNLL 2021


        </div>
        
    </div>

</body>
